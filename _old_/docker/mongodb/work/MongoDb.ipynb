{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdcdc8fe-8abc-49db-b0e5-8bbba96ebd9e",
   "metadata": {},
   "source": [
    "This command downloads and installs the mongo spark connector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea8e11a-e7b9-49df-a356-88ab43e90501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2723k  100 2723k    0     0  9621k      0 --:--:-- --:--:-- --:--:-- 9621k\n"
     ]
    }
   ],
   "source": [
    "! sudo curl https://repo1.maven.org/maven2/org/mongodb/spark/mongo-spark-connector_2.12/3.0.1/mongo-spark-connector_2.12-3.0.1-assembly.jar --output /usr/local/spark/jars/mongo-spark-connector_2.12-3.0.1-assembly.jar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6447b32b-3c40-4217-9f19-9e44056cb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85841bcc-66ef-4d96-b3b4-8f85350a395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/10/18 18:05:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://admin:mongopw@mongo:27017/demo.feedback?authSource=admin\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://admin:mongopw@mongo:27017/demo.feedback?authSource=admin\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25fea0bf-e562-4344-b896-7b7d6127f046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- alpha2Code: string (nullable = true)\n",
      " |-- alpha3Code: string (nullable = true)\n",
      " |-- altSpellings: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- area: double (nullable = true)\n",
      " |-- borders: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- callingCodes: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- capital: string (nullable = true)\n",
      " |-- currencies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- demonym: string (nullable = true)\n",
      " |-- gini: double (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- latlng: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- nativeName: string (nullable = true)\n",
      " |-- numericCode: string (nullable = true)\n",
      " |-- population: long (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- relevance: string (nullable = true)\n",
      " |-- subregion: string (nullable = true)\n",
      " |-- timezones: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- topLevelDomain: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- translations: struct (nullable = true)\n",
      " |    |-- de: string (nullable = true)\n",
      " |    |-- es: string (nullable = true)\n",
      " |    |-- fr: string (nullable = true)\n",
      " |    |-- it: string (nullable = true)\n",
      " |    |-- ja: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countries = spark.read.json(\"/home/jovyan/datasets/json-samples/europe.json\")\n",
    "countries.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9e70487-73b4-4c2a-9b6d-43980dee97d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write mode() can be \"append\" or \"overwrite\"\n",
    "countries.write.format(\"mongo\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"database\",\"demo\") \\\n",
    "    .option(\"collection\",\"countries\") \\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad1063a-d3f1-4a07-8ea8-efe34d2c531f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read\n",
    "df = spark.read.format(\"mongo\") \\\n",
    "    .option(\"database\",\"demo\") \\\n",
    "    .option(\"collection\",\"countries\") \\\n",
    "    .load()\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3aba45d2-dd15-4ca2-9635-3da0fa5262f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data need not be in json format, but when its written to Mongo, it gets stored in that format:\n",
    "spark.read.csv(\"/home/jovyan/datasets/ufo-sightings/ufo-sightings-2016*.csv\", inferSchema=True, header=True) \\\n",
    "    .write.format(\"mongo\").mode(\"overwrite\").option(\"database\",\"ufo\").option(\"collection\",\"sightings\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f58c36-6af5-43ce-ad42-82fa3a8e231a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be81598-d838-489b-8e7d-9e525ebcb6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
