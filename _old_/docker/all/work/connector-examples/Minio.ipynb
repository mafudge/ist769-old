{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186de43b-7642-4217-be35-684874c6f61c",
   "metadata": {},
   "source": [
    "# Example to Read / Write to Minio / S3 bucket with Spark\n",
    "\n",
    "NOTE: Read / Write from Minio like you would the local file system. The different is the path uses `s3a://`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6ec98d-1d75-4f77-a899-144ce7e3e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60a2a9a3-6e79-44c9-a7d7-a9ebf297275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MINIO CONFIGURATION\n",
    "s3_host = \"minio\"\n",
    "s3_url = f\"http://{s3_host}:9000\"\n",
    "s3_key = \"minio\"\n",
    "s3_secret = \"SU2orange!\"\n",
    "s3_bucket = \"minio-example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16a6e22e-429d-47e2-ba58-4f336d0336a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-972ed01f-c17a-430b-9617-ee8b9a2fa7ea;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound org.apache.hadoop#hadoop-aws;3.1.2 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.271 in central\n",
      ":: resolution report :: resolve 134ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.271 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.1.2 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-972ed01f-c17a-430b-9617-ee8b9a2fa7ea\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/4ms)\n",
      "21/11/16 21:08:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Spark init\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "    .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:3.1.2\")\\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", s3_url) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", s3_key) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", s3_secret) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff89a7f1-17a3-4051-82c8-1a430913bae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.82</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3098.12</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>251.11</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1725.05</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128.39</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>212.55</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78.00</td>\n",
       "      <td>NET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>497.00</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>823.80</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.11</td>\n",
       "      <td>TWTR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price symbol\n",
       "0   126.82   AAPL\n",
       "1  3098.12   AMZN\n",
       "2   251.11     FB\n",
       "3  1725.05   GOOG\n",
       "4   128.39    IBM\n",
       "5   212.55   MSFT\n",
       "6    78.00    NET\n",
       "7   497.00   NFLX\n",
       "8   823.80   TSLA\n",
       "9    45.11   TWTR"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read local data\n",
    "df = spark.read.option(\"multiline\",\"true\").json(\"/home/jovyan/datasets/json-samples/stocks.json\")\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fc4513b-4d4b-4ccc-b943-dd249d64ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to minio as CSV file - MAKE SURE BUCKET EXISTS !\n",
    "df.write.mode(\"Overwrite\").csv(\"s3a://minio-example/stocks.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b94b3caa-49d6-40cc-87a6-e282ebffc407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.82</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3098.12</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>251.11</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1725.05</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128.39</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>212.55</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78.0</td>\n",
       "      <td>NET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>497.0</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>823.8</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.11</td>\n",
       "      <td>TWTR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price symbol\n",
       "0   126.82   AAPL\n",
       "1  3098.12   AMZN\n",
       "2   251.11     FB\n",
       "3  1725.05   GOOG\n",
       "4   128.39    IBM\n",
       "5   212.55   MSFT\n",
       "6     78.0    NET\n",
       "7    497.0   NFLX\n",
       "8    823.8   TSLA\n",
       "9    45.11   TWTR"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read back from minio\n",
    "df1 = spark.read.csv(\"s3a://minio-example/stocks.csv\",header=True)\n",
    "df1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dfeead-c71c-4a6e-979b-ed78af9e71d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746eb138-d4c5-4ffd-9860-e16129b0aeee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41f61b-1772-4829-bcfa-a363ebc71733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
