# IST769 Lab K
## Streaming Databases With the Kafka

In this lab, we will explore Kafka.

## Outcomes

At the end of this lab you should be able to:

- Use Apache Kafka 
- Query Kafka topics with KSQL
- Publish and consume messages from Kafka with Python.

## Setup

1. Open the terminal window in your `ist769` folder.
1. Change the current working directory to `docker/kafka`:  
`ist769$ cd docker/kafka`
1. Bring up the environment:  
`kafka$ docker-compose up -d`
1. Make sure the 9 containers in this setup are running! Most importantly: `broker
`kafka$ docker-compose ps`
1. Get the URL with access token for jupyter. It will be a url in the jupyter logs:  
`kafka$ docker-compose logs jupyter`
1. Login to the jupyter Web UI http://localhost:8888 and run the `Weblogs-Producer.ipynb` notebook to start generating data.
1. Log-in to the KSQL shell:  
`kafka$ docker-compose exec ksqldb-cli ksql http://ksqldb-server:8088`


## Exercises

For each of the following provide a screenshot as evidence the commands were executed. Include all commands necessary to complete the question including those to add data and display output. Make sure your name or netid appear in the screenshot.

## Questions

**Q1.**	Write KSQL to create a stream named weblogs from the JSON keys in the weblogs Kafka topic. Make sure to set the TIMESTAMP property to the timestamp from the stream. 

**Q2.**	Write a KSQL statement create a persistent stream/table called homepage which only displays visitors to the root of the website (/). It should display all columns from the weblogs stream.

**Q3.**	Write a KSQL statement to count operating systems users (os) in 60 second windows. After 60 seconds, the counter should reset, and counts should begin again.

**Q4.**	Write a KSQL persistent stream/table called user_activity which will display a count of user activity on the website within 1-minute sessions. 

**Q5.**	Write a KSQL statement to display users who have more than 1 pages of activity in a 1-minute window. 

**Q6.** In Jupyter, write a program to subscribe to the homepage topic generated by the stream/table in Q2 and and display the messages to the console. NOTE: We could easily write these to elasticsearch, but we will not do that in this lab.


