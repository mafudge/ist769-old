{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "186de43b-7642-4217-be35-684874c6f61c",
   "metadata": {},
   "source": [
    "# Example to Read / Write to Cassandra with Spark\n",
    "\n",
    "Documentation: https://github.com/datastax/spark-cassandra-connector/blob/master/doc/15_python.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e6ec98d-1d75-4f77-a899-144ce7e3e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60a2a9a3-6e79-44c9-a7d7-a9ebf297275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASSANDRA CONFIGURATION\n",
    "cassandra_host = \"cassandra\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16a6e22e-429d-47e2-ba58-4f336d0336a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector-assembly_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-653d0eb2-bc9f-45e3-84d9-25a0b47973b6;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0 in central\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-assembly_2.12/3.1.0/spark-cassandra-connector-assembly_2.12-3.1.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0!spark-cassandra-connector-assembly_2.12.jar (396ms)\n",
      ":: resolution report :: resolve 462ms :: artifacts dl 398ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   1   |   1   |   0   ||   1   |   1   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-653d0eb2-bc9f-45e3-84d9-25a0b47973b6\n",
      "\tconfs: [default]\n",
      "\t1 artifacts copied, 0 already retrieved (14544kB/37ms)\n",
      "21/11/16 22:07:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/16 22:07:46 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/11/16 22:07:46 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "21/11/16 22:07:46 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "21/11/16 22:07:46 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "21/11/16 22:07:46 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n"
     ]
    }
   ],
   "source": [
    "# Spark init\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "      .config(\"spark.cassandra.connection.host\", cassandra_host) \\\n",
    "      .config(\"spark.jars.packages\",\"com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.1.0\")\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff89a7f1-17a3-4051-82c8-1a430913bae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.82</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3098.12</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>251.11</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1725.05</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128.39</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>212.55</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78.00</td>\n",
       "      <td>NET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>497.00</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>823.80</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.11</td>\n",
       "      <td>TWTR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price symbol\n",
       "0   126.82   AAPL\n",
       "1  3098.12   AMZN\n",
       "2   251.11     FB\n",
       "3  1725.05   GOOG\n",
       "4   128.39    IBM\n",
       "5   212.55   MSFT\n",
       "6    78.00    NET\n",
       "7   497.00   NFLX\n",
       "8   823.80   TSLA\n",
       "9    45.11   TWTR"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read local data\n",
    "df = spark.read.option(\"multiline\",\"true\").json(\"/home/jovyan/datasets/json-samples/stocks.json\")\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19bec77e-458d-4fea-96b0-bd4c84d7382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE NEED A TABLE BEFORE WE CAN WRITE, Using Plain old Python\n",
    "!pip install -q cassandra-driver\n",
    "from cassandra.cluster import Cluster\n",
    "with Cluster([cassandra_host]) as cluster:\n",
    "    session = cluster.connect()\n",
    "    session.execute(\"CREATE KEYSPACE IF NOT EXISTS example WITH replication={ 'class': 'SimpleStrategy', 'replication_factor' : 1 };\")\n",
    "    session.execute(\"CREATE TABLE IF NOT EXISTS example.stocks (symbol text, price decimal, primary key (symbol));\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5fc4513b-4d4b-4ccc-b943-dd249d64ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to back to our newly-minted Cassandra table, Append mode is okay here because of Cassandra's default upsert behavior.\n",
    "df.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "  .mode(\"Append\")\\\n",
    "  .option(\"table\", \"stocks\")\\\n",
    "  .option(\"keyspace\",\"example\")\\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b94b3caa-49d6-40cc-87a6-e282ebffc407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TWTR</td>\n",
       "      <td>45.110000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IBM</td>\n",
       "      <td>128.390000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FB</td>\n",
       "      <td>251.110000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NFLX</td>\n",
       "      <td>497.000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NET</td>\n",
       "      <td>78.000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>126.820000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>3098.120000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>823.800000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>1725.050000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>212.550000000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol                    price\n",
       "0   TWTR    45.110000000000000000\n",
       "1    IBM   128.390000000000000000\n",
       "2     FB   251.110000000000000000\n",
       "3   NFLX   497.000000000000000000\n",
       "4    NET    78.000000000000000000\n",
       "5   AAPL   126.820000000000000000\n",
       "6   AMZN  3098.120000000000000000\n",
       "7   TSLA   823.800000000000000000\n",
       "8   GOOG  1725.050000000000000000\n",
       "9   MSFT   212.550000000000000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read back from Cassandra\n",
    "df1 =spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .options(table=\"stocks\", keyspace=\"example\") \\\n",
    "    .load()\n",
    "df1.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dfeead-c71c-4a6e-979b-ed78af9e71d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746eb138-d4c5-4ffd-9860-e16129b0aeee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff41f61b-1772-4829-bcfa-a363ebc71733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
